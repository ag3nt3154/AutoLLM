{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPTQConfig\n",
    "\n",
    "quantization_config = GPTQConfig(bits=4, use_exllama=True, exllama_config={\"version\": 2})\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Available models:\n",
      "Llama3.1_8B_Instruct_GPTQ_INT4\n",
      "Llama3.2_3B_Instruct_GPTQ_4bit_Vortex-v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexr\\miniconda3\\envs\\llm2\\Lib\\site-packages\\transformers\\quantizers\\auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n",
      "  warnings.warn(warning_msg)\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "c:\\Users\\alexr\\miniconda3\\envs\\llm2\\Lib\\site-packages\\transformers\\modeling_utils.py:5006: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "from AutoLLM.models.llama3_instruct import Llama3InstructModel\n",
    "\n",
    "l3m = Llama3InstructModel(model_store_dir='./model_store')\n",
    "l3m.show_available_models()\n",
    "\n",
    "model_name = \"Llama3.2_3B_Instruct_GPTQ_4bit_Vortex-v3\"\n",
    "\n",
    "l3m.load_tokenizer_from_path(\n",
    "    model_name=model_name,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "l3m.load_model_from_path(\n",
    "    model_name=model_name,\n",
    "    use_safetensors=True,\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map='cuda:0',\n",
    ")\n",
    "\n",
    "l3m.build_pipeline(\n",
    "    return_full_text=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# max_new_tokens=get_attr(kwargs, 'max_new_tokens', 1024),\n",
    "# temperature=get_attr(kwargs, 'temperature', 0.2),\n",
    "# top_p=get_attr(kwargs, 'top_p', 0.95),\n",
    "# top_k=get_attr(kwargs, 'top_k', 40),\n",
    "# do_sample=get_attr(kwargs, 'do_sample', True),\n",
    "# return_full_text=get_attr(kwargs, 'return_full_text', False),\n",
    "# add_special_tokens=get_attr(kwargs, 'add_special_tokens', False),\n",
    "# continue_final_message=get_attr(kwargs, 'continue_final_message', False),\n",
    "# assistant_model=self.assistant_model if speculative_decoding else None,\n",
    "#  # Set up quantization configuration\n",
    "# quantization_config = GPTQConfig(\n",
    "#     bits=get_attr(kwargs, 'bits', 4),\n",
    "#     use_exllama=get_attr(kwargs, 'use_exllama', True),\n",
    "#     exllama_config=get_attr(kwargs, 'exllama_config', {\"version\": 2}),\n",
    "# )\n",
    "\n",
    "# device_map=device_map,\n",
    "# quantization_config=quantization_config,\n",
    "# torch_dtype=get_attr(kwargs, 'torch_dtype', torch.float16),\n",
    "# low_cpu_mem_usage=get_attr(kwargs, 'low_cpu_mem_usage', True),\n",
    "# trust_remote_code=get_attr(kwargs, 'trust_remote_code', True),\n",
    "# use_safetensors=get_attr(kwargs, 'use_safetensors', True),\n",
    "# **kwargs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Nov 2024\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is the meaning of life?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Time taken: 40.084494829177856 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The meaning of life is a complex and subjective question that has been debated by philosophers, theologians, scientists, and thinkers for centuries. There is no one definitive answer, as it varies greatly depending on cultural, personal, and philosophical perspectives.\\n\\nThat being said, here are some possible perspectives on the meaning of life:\\n\\n1. **Biological perspective**: From a biological standpoint, the meaning of life is to survive and reproduce, ensuring the continuation of one's genes and species.\\n2. **Philosophical perspective**: Philosophers have offered various interpretations, such as:\\n\\t* Existentialism: Life has no inherent meaning, and it's\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = [\n",
    "    {\n",
    "        'role': 'system', \n",
    "        'content': 'You are a helpful assistant.'\n",
    "    }, \n",
    "    {\n",
    "        'role': 'user', \n",
    "        'content': \"What is the meaning of life?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "l3m.run(\n",
    "    prompt=chat,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    do_sample=True,\n",
    "    return_full_text=False,\n",
    "    add_special_tokens=True,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['Llama3.1_8B_Instruct_GPTQ_INT4', 'Llama3.2_3B_Instruct_GPTQ_4bit_Vortex-v3']\n",
      "FlashAttention is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexr\\miniconda3\\envs\\llm2\\Lib\\site-packages\\transformers\\quantizers\\auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n",
      "  warnings.warn(warning_msg)\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "c:\\Users\\alexr\\miniconda3\\envs\\llm2\\Lib\\site-packages\\transformers\\modeling_utils.py:5006: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x1cf52033c90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AutoLLM.Models.llama3_model import Llama3InstructModel\n",
    "\n",
    "model_store_path = './model_store/'\n",
    "l3im = Llama3InstructModel(model_directory=model_store_path)\n",
    "l3im.build_pipeline_from_path('Llama3.2_3B_Instruct_GPTQ_4bit_Vortex-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'you are a helpful assistant'}, {'role': 'user', 'content': 'what is the meaning of life?'}]\n",
      "Output: assistant\n",
      "\n",
      "The meaning of life is a complex and subjective question that has been debated by philosophers, theologians, scientists, and thinkers for centuries. There is no one definitive answer, as it varies greatly depending on cultural, personal, and philosophical perspectives.\n",
      "\n",
      "Here are some possible perspectives on the meaning of life:\n",
      "\n",
      "1. **Biological perspective**: From a biological standpoint, the meaning of life is to survive and reproduce, ensuring the continuation of one's genes and species.\n",
      "2. **Philosophical perspective**: Philosophers have offered various definitions, such as:\n",
      "\t* Existentialism: Life has no inherent meaning, and it's up to each individual to create their own purpose.\n",
      "\t* Hedonism: The meaning of life is to seek pleasure and happiness.\n",
      "\t* Stoicism: The meaning of life is to live in accordance with reason and virtue.\n",
      "\t* Nihilism: Life has no inherent meaning, and it's ultimately meaningless.\n",
      "3. **Spiritual perspective**: Many spiritual traditions believe that the meaning of life is to:\n",
      "\t* Connect with a higher power or divine being.\n",
      "\t* Achieve spiritual enlightenment or self-realization.\n",
      "\t* Follow a set of moral principles or values.\n",
      "4. **Personal perspective**: Ultimately, the meaning of life is a deeply personal question that each individual must answer for themselves. It may involve:\n",
      "\t* Pursuing one's passions and interests.\n",
      "\t* Building meaningful relationships and connections.\n",
      "\t* Contributing to society or making a positive impact.\n",
      "\t* Finding personal growth and self-fulfillment.\n",
      "\n",
      "In conclusion, the meaning of life is a multifaceted and subjective question that may have different answers depending on individual perspectives and values. What do you think is the meaning of life?\n",
      "Elapsed Time: 92.29 seconds\n",
      "Throughput: 3.80 tokens/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"assistant\\n\\nThe meaning of life is a complex and subjective question that has been debated by philosophers, theologians, scientists, and thinkers for centuries. There is no one definitive answer, as it varies greatly depending on cultural, personal, and philosophical perspectives.\\n\\nHere are some possible perspectives on the meaning of life:\\n\\n1. **Biological perspective**: From a biological standpoint, the meaning of life is to survive and reproduce, ensuring the continuation of one's genes and species.\\n2. **Philosophical perspective**: Philosophers have offered various definitions, such as:\\n\\t* Existentialism: Life has no inherent meaning, and it's up to each individual to create their own purpose.\\n\\t* Hedonism: The meaning of life is to seek pleasure and happiness.\\n\\t* Stoicism: The meaning of life is to live in accordance with reason and virtue.\\n\\t* Nihilism: Life has no inherent meaning, and it's ultimately meaningless.\\n3. **Spiritual perspective**: Many spiritual traditions believe that the meaning of life is to:\\n\\t* Connect with a higher power or divine being.\\n\\t* Achieve spiritual enlightenment or self-realization.\\n\\t* Follow a set of moral principles or values.\\n4. **Personal perspective**: Ultimately, the meaning of life is a deeply personal question that each individual must answer for themselves. It may involve:\\n\\t* Pursuing one's passions and interests.\\n\\t* Building meaningful relationships and connections.\\n\\t* Contributing to society or making a positive impact.\\n\\t* Finding personal growth and self-fulfillment.\\n\\nIn conclusion, the meaning of life is a multifaceted and subjective question that may have different answers depending on individual perspectives and values. What do you think is the meaning of life?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_msg = 'you are a helpful assistant'\n",
    "msg = 'what is the meaning of life?'\n",
    "\n",
    "l3im.run_with_raw_prompt(sys_msg, msg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': \"Label the sentiment of the text as positive or negative. Show your reasoning. Repeat the prompt.\\n\\n=======\\n\\nFollow the following format:\\n\\nQuestion: Label the sentiment of the text as positive or negative.\\n\\nText: The text to be labeled.\\n\\nReasoning: Let's think step by step in order to produce the answer.\\n\\nAnswer: Label the sentiment of the text as positive or negative.\\n\\n=======\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I love this product!\\n\\nReasoning: The text is positive because it expresses love for the product.\\n\\nAnswer: Positive\\n\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I hate this product!\\n\\nReasoning: The text is negative because it expresses hate for the product.\\n\\nAnswer: Negative\\n\\n\\n=======\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I am incredibly satisfied with this product. It has helped me so much.\\n\\n\"}]\n",
      "\n",
      "\n",
      "[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': \"Label the sentiment of the text as positive or negative. Show your reasoning. Repeat the prompt.\\n\\n=======\\n\\nFollow the following format:\\n\\nQuestion: Label the sentiment of the text as positive or negative.\\n\\nText: The text to be labeled.\\n\\nReasoning: Let's think step by step in order to produce the answer.\\n\\nAnswer: Label the sentiment of the text as positive or negative.\\n\\n=======\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I love this product!\\n\\nReasoning: The text is positive because it expresses love for the product.\\n\\nAnswer: Positive\\n\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I hate this product!\\n\\nReasoning: The text is negative because it expresses hate for the product.\\n\\nAnswer: Negative\\n\\n\\n=======\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I am incredibly satisfied with this product. It has helped me so much.\\n\\n\"}]\n",
      "\n",
      "Output: assistant\n",
      "\n",
      "Question: Is the following text positive or negative?\n",
      "\n",
      "Text: I am incredibly satisfied with this product. It has helped me so much.\n",
      "\n",
      "Reasoning: \n",
      "Step 1: The text uses the word \"incredibly\" which is an adverb that emphasizes the degree of satisfaction.\n",
      "Step 2: The text states that the product has helped the person, which implies a positive outcome.\n",
      "Step 3: The overall tone of the text is enthusiastic and grateful.\n",
      "\n",
      "Answer: Positive\n",
      "\n",
      "Elapsed Time: 26.92 seconds\n",
      "Throughput: 3.68 tokens/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'assistant\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I am incredibly satisfied with this product. It has helped me so much.\\n\\nReasoning: \\nStep 1: The text uses the word \"incredibly\" which is an adverb that emphasizes the degree of satisfaction.\\nStep 2: The text states that the product has helped the person, which implies a positive outcome.\\nStep 3: The overall tone of the text is enthusiastic and grateful.\\n\\nAnswer: Positive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AutoLLM.Prompt_Generator.Prompt_Generator import PromptGenerator\n",
    "\n",
    "config = [\n",
    "    {\n",
    "        \"name\": \"Question\",\n",
    "        \"description\": \"Label the sentiment of the text as positive or negative.\",\n",
    "        \"placeholder\": \"<<question>>\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Text\",\n",
    "        \"description\": \"The text to be labeled.\",\n",
    "        \"placeholder\": \"<<text>>\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Reasoning\",\n",
    "        \"description\": \"Let's think step by step in order to produce the answer.\",\n",
    "        \"placeholder\": \"<<reasoning>>\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Answer\",\n",
    "        \"description\": \"Label the sentiment of the text as positive or negative.\",\n",
    "        \"placeholder\": \"<<answer>>\",\n",
    "    },\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"Question\": \"Is the following text positive or negative?\",\n",
    "        \"Text\": \"I love this product!\",\n",
    "        \"Reasoning\": \"The text is positive because it expresses love for the product.\",\n",
    "        \"Answer\": \"Positive\",\n",
    "    },\n",
    "    {\n",
    "        \"Question\": \"Is the following text positive or negative?\",\n",
    "        \"Text\": \"I hate this product!\",\n",
    "        \"Reasoning\": \"The text is negative because it expresses hate for the product.\",\n",
    "        \"Answer\": \"Negative\",\n",
    "    },\n",
    "]\n",
    "input = {\n",
    "    \"Question\": \"Is the following text positive or negative?\",\n",
    "    \"Text\": \"I am incredibly satisfied with this product. It has helped me so much.\",\n",
    "}\n",
    "\n",
    "pg = PromptGenerator()\n",
    "prompt = pg.build_prompt(\n",
    "    prompt_config=config,\n",
    "    instruction=\"Label the sentiment of the text as positive or negative.\",\n",
    "    input_data=input,\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    chain_of_thought=\"Show your reasoning.\",\n",
    "    echo=\"Repeat the prompt.\",\n",
    "    examples=examples,\n",
    "    chat=True,\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "config = {\n",
    "    'temperature': 1e-20,\n",
    "    'continue_final_message': True,\n",
    "}\n",
    "\n",
    "print('\\n')\n",
    "l3im.run_with_chat(prompt, True, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': \"Label the sentiment of the text as positive or negative. Show your reasoning. Repeat the prompt.\\n\\n=======\\n\\nFollow the following format:\\n\\nQuestion: Label the sentiment of the text as positive or negative.\\n\\nText: The text to be labeled.\\n\\nReasoning: Let's think step by step in order to produce the answer.\\n\\nAnswer: Label the sentiment of the text as positive or negative.\\n\\n=======\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I love this product!\\n\\nReasoning: The text is positive because it expresses love for the product.\\n\\nAnswer: Positive\\n\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I hate this product!\\n\\nReasoning: The text is negative because it expresses hate for the product.\\n\\nAnswer: Negative\\n\\n\\n=======\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I love this product!\\n\\nReasoning: \"}]\n",
      "Output: assistant\n",
      "\n",
      "Here is the revised response:\n",
      "\n",
      "Question: Is the following text positive or negative?\n",
      "\n",
      "Text: I love this product!\n",
      "\n",
      "Reasoning: \n",
      "Step 1: The text contains the word \"love\", which is a strong positive emotion.\n",
      "Step 2: The word \"love\" is often associated with strong affection and enthusiasm, which suggests a positive sentiment.\n",
      "Step 3: There is no negative language or tone in the text, which further supports the positive sentiment.\n",
      "\n",
      "Answer: Positive\n",
      "Elapsed Time: 34.14 seconds\n",
      "Throughput: 2.87 tokens/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'assistant\\n\\nHere is the revised response:\\n\\nQuestion: Is the following text positive or negative?\\n\\nText: I love this product!\\n\\nReasoning: \\nStep 1: The text contains the word \"love\", which is a strong positive emotion.\\nStep 2: The word \"love\" is often associated with strong affection and enthusiasm, which suggests a positive sentiment.\\nStep 3: There is no negative language or tone in the text, which further supports the positive sentiment.\\n\\nAnswer: Positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
